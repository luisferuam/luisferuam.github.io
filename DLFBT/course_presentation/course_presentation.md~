% Deep Learning Fundamentals and Basic Tools
% Luis F. Lago FernÃ¡ndez
% Deep Learning for Audio and Video Signal Processing

### Course presentation

- Eat eggs
- Drink coffee
- asdf
- asdfa
- 5555

### Covid19 special measures

- Eat spaghetti
- Drink wine

### Introduction to deep learning

- What is deep learning?
- Why now?

### What is Deep Learning?

- A subfield of Machine Learning: learn without being explicitly programmed
- Make predictions on data using Neural Networks
- Deep neural networks: many layers

### Why deep learning now?

- Lots of data
- Increase in computational power (GPUs, parallelization)
- New programming tools, algorithms and tricks

### Machine Learning fundamentals

Recommended reading: [https://www.deeplearningbook.org/contents/ml.html](https://www.deeplearningbook.org/contents/ml.html)

### What is Machine Learning?

- Field of study that gives computers the ability to learn without
being explicitly programmed to. (Attributed to **A. Samuel, 1959**)

- Subfield of AI that studies computer algorithms that improve automatically through experience.
([Wikipedia, 2020](https://en.wikipedia.org/wiki/Machine_learning))

### Different learning tasks

- *Supervised* machine learning
  - Classification
  - Regression

- *Unsupervised* machine learning

- *Semi-supervised* machine learning

- *Reinforcement* learning

### Supervised machine learning - definitions

- The problem data is the set of patterns $\{({\bf x}_{1} , t_{1}), ({\bf x}_{2}, t_{2}), ..., ({\bf x}_{n}, t_{n})\}$, where:

  - ${\bf x}_{i}$ is the *attribute vector* for pattern $i$
  - $t_{i}$ is the *target* (variable to predict) for pattern $i$
  - $n$ is the total number of patterns

- The goal is to predict the target $t_{i}$ given the attribute vector ${\bf x}_{i}$

### Parametric models for classification (regression)

- A *classifier* (*regressor*) is a function $f({\bf x}, \theta)$ that assigns each pattern ${\bf x}_i$ an estimation of its target value: $y_{i} = f({\bf x}_{i} , \theta) \approx t_{i}$

- *Model training*: tune the model parameters $\theta$ in order to minimize a *loss function* $L(y_{i}, t_{i})$

- Different function families define different types of models: Neural Networks, SVMs, etc.

### XXXX Title missing XXXX

![](Images/ML-algorithms.png){width=700px}



### Supervised machine learning - an example

The *Iris plant dataset* (R.A. Fisher, 1936)

![](https://drive.google.com/uc?id=1aN5FeKpb1SBUhuglGNIe97-HFB0Naiaz)

- Classify Iris plant samples into 3 subspecies: *Setosa*, *Virginica* and *Versicolor*
- Use the width and length of petal and sepal as attributes 

### Supervised machine learning - an example

The *Iris plant dataset* (R.A. Fisher, 1936)

![](Images/iris-table.png){width=700px}

### Supervised machine learning - an example

The *Iris plant dataset* (R.A. Fisher, 1936)

![](Images/iris-plots.png){width=700px}

Classification or regression?


### Supervised machine learning - second example

The *Boston Housing* problem

![](https://drive.google.com/uc?id=1aN5FeKpb1SBUhuglGNIe97-HFB0Naiaz)

- Classify Iris plant samples into 3 subspecies: *Setosa*, *Virginica* and *Versicolor*
- Use the width and length of petal and sepal as attributes 

### Supervised machine learning - second example

The *Boston Housing* problem

![](Images/iris-table.png){width=700px}

### Supervised machine learning - second example

The *Boston Housing* problem

![](Images/iris-plots.png){width=700px}

Classification or regression?


### The ML design cycle

Model construction/training is just one single step in a much bigger process

![](Images/ML-design-cycle.png){width=700px}

### Model evaluation and selection

- How to assess the quality of a trained model
- How to compare two different models
- Different evaluation metrics: loss, accuracy, confusion matrix, ROC analysis, etc.
- Hyper-parameter tuning
- Model validation

### Model evaluation and selection - Example

![](Images/duda-hart-two-models.png){width=700px}

Which model is better?

### Model complexity and generalization

![](Images/overfitting.png){width=700px}

- Complex models are able to better adapt to the training data
- *Overfitting*: too much adaptation to the training data may lead to a poor generalization

### Training, validation, test

![](Images/train-val-test.png){width=500px}

- Use different data for training and evaluating the model

- Early stoping

### (Proper) Regularization

- Modify the loss function by introducing a term that penalizes model complexity

LOSS = ERROR + COMPLEXITY

### Review: Core topics

- Neural networks are supervised, parametric model for classification and regression

### Next day

- Neural networks with one single neuron

- Linear regression

- Logistic regression (classification)

### TESTS

```{js}[1-2|3|4]
    let a = 1;
    let b = 2;
    let c = x => 1 + 2 + x;
    c(3);
```