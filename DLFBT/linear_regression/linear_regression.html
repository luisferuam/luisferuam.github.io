<!DOCTYPE html>
<!--
==============================================================================
           "GitHub HTML5 Pandoc Template" v2.2 — by Tristano Ajmone
==============================================================================
Copyright © Tristano Ajmone, 2017-2020, MIT License (MIT). Project's home:

- https://github.com/tajmone/pandoc-goodies

The CSS in this template reuses source code taken from the following projects:

- GitHub Markdown CSS: Copyright © Sindre Sorhus, MIT License (MIT):
  https://github.com/sindresorhus/github-markdown-css

- Primer CSS: Copyright © 2016-2017 GitHub Inc., MIT License (MIT):
  http://primercss.io/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The MIT License

Copyright (c) Tristano Ajmone, 2017-2020 (github.com/tajmone/pandoc-goodies)
Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
Copyright (c) 2017 GitHub Inc.

"GitHub Pandoc HTML5 Template" is Copyright (c) Tristano Ajmone, 2017-2020,
released under the MIT License (MIT); it contains readaptations of substantial
portions of the following third party softwares:

(1) "GitHub Markdown CSS", Copyright (c) Sindre Sorhus, MIT License (MIT).
(2) "Primer CSS", Copyright (c) 2016 GitHub Inc., MIT License (MIT).

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
==============================================================================-->
<html>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Luis F. Lago-Fernández" />
  <title>Linear Regression</title>
  <style type="text/css">
@charset "UTF-8";.markdown-body{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;color:#24292e;font-family:-apple-system,system-ui,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";font-size:16px;line-height:1.5;word-wrap:break-word;box-sizing:border-box;min-width:200px;max-width:980px;margin:0 auto;padding:45px}.markdown-body a{color:#0366d6;background-color:transparent;text-decoration:none;-webkit-text-decoration-skip:objects}.markdown-body a:active,.markdown-body a:hover{outline-width:0}.markdown-body a:hover{text-decoration:underline}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body strong{font-weight:600}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1{font-size:2em;margin:.67em 0;padding-bottom:.3em;border-bottom:1px solid #eaecef}.markdown-body h2{padding-bottom:.3em;font-size:1.5em;border-bottom:1px solid #eaecef}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#6a737d}.markdown-body img{border-style:none}.markdown-body svg:not(:root){overflow:hidden}.markdown-body hr{box-sizing:content-box;height:.25em;margin:24px 0;padding:0;overflow:hidden;background-color:#e1e4e8;border:0}.markdown-body hr::before{display:table;content:""}.markdown-body hr::after{display:table;clear:both;content:""}.markdown-body input{margin:0;overflow:visible;font:inherit;font-family:inherit;font-size:inherit;line-height:inherit}.markdown-body [type=checkbox]{box-sizing:border-box;padding:0}.markdown-body *{box-sizing:border-box}.markdown-body blockquote{margin:0}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol ol,.markdown-body ul ol{list-style-type:lower-roman}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body ol ol ol,.markdown-body ol ul ol,.markdown-body ul ol ol,.markdown-body ul ul ol{list-style-type:lower-alpha}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dd{margin-left:0}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body code{font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace}.markdown-body pre{font:12px SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;word-wrap:normal}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body blockquote{padding:0 1em;color:#6a737d;border-left:.25em solid #dfe2e5}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body table{display:block;width:100%;overflow:auto;border-spacing:0;border-collapse:collapse}.markdown-body table th{font-weight:600}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #dfe2e5}.markdown-body table tr{background-color:#fff;border-top:1px solid #c6cbd1}.markdown-body table tr:nth-child(2n){background-color:#f6f8fa}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body code{padding:.2em 0;margin:0;font-size:90%;background-color:rgba(27,31,35,.05);border-radius:3px}.markdown-body code::after,.markdown-body code::before{letter-spacing:-.2em;content:" "}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:0 0;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:90%;line-height:1.45;background-color:#f6f8fa;border-radius:3px}.markdown-body pre code{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code::after,.markdown-body pre code::before{content:normal}.markdown-body .full-commit .btn-outline:not(:disabled):hover{color:#005cc5;border-color:#005cc5}.markdown-body kbd{box-shadow:inset 0 -1px 0 #959da5;display:inline-block;padding:3px 5px;font:11px/10px SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#444d56;vertical-align:middle;background-color:#fcfcfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}.markdown-body :checked+.radio-label{position:relative;z-index:1;border-color:#0366d6}.markdown-body .task-list-item{list-style-type:none}.markdown-body .task-list-item+.task-list-item{margin-top:3px}.markdown-body .task-list-item input{margin:0 .2em .25em -1.6em;vertical-align:middle}.markdown-body::before{display:table;content:""}.markdown-body::after{display:table;clear:both;content:""}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.Alert,.Error,.Note,.Success,.Warning{padding:11px;margin-bottom:24px;border-style:solid;border-width:1px;border-radius:4px}.Alert p,.Error p,.Note p,.Success p,.Warning p{margin-top:0}.Alert p:last-child,.Error p:last-child,.Note p:last-child,.Success p:last-child,.Warning p:last-child{margin-bottom:0}.Alert{color:#246;background-color:#e2eef9;border-color:#bac6d3}.Warning{color:#4c4a42;background-color:#fff9ea;border-color:#dfd8c2}.Error{color:#911;background-color:#fcdede;border-color:#d2b2b2}.Success{color:#22662c;background-color:#e2f9e5;border-color:#bad3be}.Note{color:#2f363d;background-color:#f6f8fa;border-color:#d5d8da}.Alert h1,.Alert h2,.Alert h3,.Alert h4,.Alert h5,.Alert h6{color:#246;margin-bottom:0}.Warning h1,.Warning h2,.Warning h3,.Warning h4,.Warning h5,.Warning h6{color:#4c4a42;margin-bottom:0}.Error h1,.Error h2,.Error h3,.Error h4,.Error h5,.Error h6{color:#911;margin-bottom:0}.Success h1,.Success h2,.Success h3,.Success h4,.Success h5,.Success h6{color:#22662c;margin-bottom:0}.Note h1,.Note h2,.Note h3,.Note h4,.Note h5,.Note h6{color:#2f363d;margin-bottom:0}.Alert h1:first-child,.Alert h2:first-child,.Alert h3:first-child,.Alert h4:first-child,.Alert h5:first-child,.Alert h6:first-child,.Error h1:first-child,.Error h2:first-child,.Error h3:first-child,.Error h4:first-child,.Error h5:first-child,.Error h6:first-child,.Note h1:first-child,.Note h2:first-child,.Note h3:first-child,.Note h4:first-child,.Note h5:first-child,.Note h6:first-child,.Success h1:first-child,.Success h2:first-child,.Success h3:first-child,.Success h4:first-child,.Success h5:first-child,.Success h6:first-child,.Warning h1:first-child,.Warning h2:first-child,.Warning h3:first-child,.Warning h4:first-child,.Warning h5:first-child,.Warning h6:first-child{margin-top:0}h1.title,p.subtitle{text-align:center}h1.title.followed-by-subtitle{margin-bottom:0}p.subtitle{font-size:1.5em;font-weight:600;line-height:1.25;margin-top:0;margin-bottom:16px;padding-bottom:.3em}div.line-block{white-space:pre-line}
  </style>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<article class="markdown-body">
<header>
<h1 class="title"><font color="#CA3532">Linear Regression</font></h1>
<p class="author">Luis F. Lago-Fernández</p>
<p class="date"><a href="https://colab.research.google.com/github/luisferuam/luisferuam.github.io/blob/master/DLFBT/linear_regression/linear_regression.ipynb">Open in Google Colab</a></p>
</header>
<hr>
<nav id="TOC">
<h2 class="toc-title"><font color="#CA3532">Contents</font></h2>
<ul>
<li><a href="#introduction"><font color="#CA3532">Introduction</font></a></li>
<li><a href="#linear-regression-in-1d"><font color="#CA3532">Linear regression in 1D</font></a></li>
<li><a href="#gradient-descent"><font color="#CA3532">Gradient descent</font></a>
<ul>
<li><a href="#questions"><font color="#CA3532">Questions</font></a></li>
</ul></li>
<li><a href="#linear-regression-in-arbitrary-dimension"><font color="#CA3532">Linear regression in arbitrary dimension</font></a>
<ul>
<li><a href="#exercise"><font color="#CA3532">Exercise</font></a></li>
</ul></li>
</ul>
</nav>
<hr>
<h2 id="introduction"><font color="#CA3532">Introduction</font></h2>
<p>Let's assume that we have a set of pairs <span class="math inline">\(({\bf x}_{i}, t_{i})\)</span>, with <span class="math inline">\(t_{i}\)</span> a real valued variable, and want to predict the value of <span class="math inline">\(t_{i}\)</span> from <span class="math inline">\({\bf x}_{i}\)</span> using the following linear model:</p>
<p><span class="math display">\[y_{i} = f({\bf x}_{i}) = {\bf w}^{t} {\bf x}_{i} + b,\]</span></p>
<p>where <span class="math inline">\(y_{i}\)</span> is the model estimate of <span class="math inline">\(t_{i}\)</span> for <span class="math inline">\({\bf x}_{i}\)</span>. The model depends on a set of parameters <span class="math inline">\(\theta = \{{\bf w}, b\}\)</span> that must be tuned in order to obtain a good approximation of the target variable <span class="math inline">\(t\)</span>. The general procedure is to find the parameters that minimize the sum of squared errors over the training data:</p>
<p><span class="math display">\[E = \sum_{i}\frac{1}{2}(y_{i} - t_{i})^{2}.\]</span></p>
<p>This problem has an analytic solution, but we will consider here a numerical solution using the <strong>gradient descent</strong> technique.</p>
<h2 id="linear-regression-in-1d"><font color="#CA3532">Linear regression in 1D</font></h2>
<p>As a first example we will consider a problem in 1D, where both <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(t_{i}\)</span> are scalar variables. In this case the model is simply:</p>
<p><span class="math display">\[y_{i} = w x_{i} + b.\]</span></p>
<p>The following code creates a set of 100 data points <span class="math inline">\((x_{i}, t_{i})\)</span>, with <span class="math inline">\(x_{i} \in [0, 10]\)</span> and <span class="math inline">\(t_{i}\)</span> normally distributed around <span class="math inline">\(2x_{i}+1\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="co"># Parameters:</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>a <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>b <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>xmin <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>xmax <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>noise <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a><span class="co"># Randomly generated problem data:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>x <span class="op">=</span> xmin <span class="op">+</span> np.random.rand(n)<span class="op">*</span>(xmax <span class="op">-</span> xmin)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>t <span class="op">=</span> a<span class="op">*</span>x <span class="op">+</span> b <span class="op">+</span> np.random.randn(n)<span class="op">*</span>noise</span></code></pre></div>
<p>And the following code shows how the data are distributed in the plane <span class="math inline">\((x, t)\)</span>, together with the model (without noise) used to generate the data: <span class="math inline">\(t = 2x + 1\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>plt.plot(x, t, <span class="st">&#39;o&#39;</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>plt.plot([xmin, xmax], [a<span class="op">*</span>xmin <span class="op">+</span> b, a<span class="op">*</span>xmax <span class="op">+</span> b], <span class="st">&#39;r-&#39;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>plt.ylabel(<span class="st">&quot;t&quot;</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>plt.show()</span></code></pre></div>
<p><img src="./myMediaFolder/6d364b40a34b5eb5c61cec514b8c79797c5359e7.png" /></p>
<h2 id="gradient-descent"><font color="#CA3532">Gradient descent</font></h2>
<p>To solve the linear regression model, we must find the model parameters <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span> that minimize the sum of squared errors for all the data points:</p>
<p><span class="math display">\[E = \sum_{i}\frac{1}{2}(y_{i} - t_{i})^{2}.\]</span></p>
<p>We will use a technique known as <strong>gradient descent</strong> which, starting from a random guess of the parameters, performs small steps in the direction that reduces the error most. This direction is given by the negative of the gradient. For example, if we start from parameters <span class="math inline">\((w_{0}, b_{0})\)</span>, in the next step the parameters will be updated to:</p>
<p><span class="math display">\[(w_{1}, b_{1}) = (w_{0}, b_{0}) - \eta \nabla_{(w, b)} E.\]</span></p>
<p>That is:</p>
<p><span class="math display">\[w_{1} = w_{0} - \eta \frac{\partial E}{\partial w},\]</span></p>
<p><span class="math display">\[b_{1} = b_{0} - \eta \frac{\partial E}{\partial b}.\]</span></p>
<p>In the above expressions the symbol <span class="math inline">\(\eta\)</span> is a positive constant called <strong>learning rate</strong> which determines the step size. These parameter updates are performed until convergence.</p>
<p>For the linear regression model, the partial derivatives of <span class="math inline">\(E\)</span> with respect to the model parameters are easy to obtain:</p>
<p><span class="math display">\[\frac{\partial E}{\partial w} = \sum_{i}(y_{i} - t_{i})x_{i},\]</span></p>
<p><span class="math display">\[\frac{\partial E}{\partial b} = \sum_{i}(y_{i} - t_{i}).\]</span></p>
<p>And so the update rules for <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span> are:</p>
<p><span class="math display">\[w_{t+1} = w_{t} - \eta \sum_{i}(y_{i} - t_{i})x_{i},\]</span></p>
<p><span class="math display">\[b_{t+1} = b_{t} - \eta  \sum_{i}(y_{i} - t_{i}).\]</span></p>
<p>Let us apply this model to our problem data. The first thing to do is to initialize the model parameters <span class="math inline">\((w, b)\)</span> to random values:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>w <span class="op">=</span> np.random.randn()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>b <span class="op">=</span> np.random.randn()</span></code></pre></div>
<p>We don't expect that this initial random guess provides any good approximation of <span class="math inline">\(t\)</span> given <span class="math inline">\(x\)</span>, as demonstrated by the following piece of code:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>plt.plot(x, t, <span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;real data&#39;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>plt.plot([xmin, xmax], [w<span class="op">*</span>xmin <span class="op">+</span> b, w<span class="op">*</span>xmax <span class="op">+</span> b], <span class="st">&#39;r-&#39;</span>, label<span class="op">=</span><span class="st">&#39;model&#39;</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>plt.ylabel(<span class="st">&quot;t&quot;</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>plt.legend()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>plt.show()</span></code></pre></div>
<p><img src="./myMediaFolder/1b2779e9bfea401a3d1d6347d51d60e69893d112.png" /></p>
<p>We must perform several gradient descent steps before the algorithm converges to a good solution:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>num_iters <span class="op">=</span> <span class="dv">8</span> <span class="co"># number of iterations</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>eta <span class="op">=</span> <span class="fl">0.0001</span>  <span class="co"># learning rate</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a>    y <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>    y_minus_t <span class="op">=</span> y <span class="op">-</span> t</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>    dw <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t<span class="op">*</span>x)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    db <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    w <span class="op">-=</span> eta<span class="op">*</span>dw </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a>    b <span class="op">-=</span> eta<span class="op">*</span>db </span></code></pre></div>
<p>If we plot the new solution we observe a much better approximation of the data points by the linear model:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>plt.plot(x, t, <span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;real data&#39;</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>plt.plot([xmin, xmax], [w<span class="op">*</span>xmin <span class="op">+</span> b, w<span class="op">*</span>xmax <span class="op">+</span> b], <span class="st">&#39;r-&#39;</span>, label<span class="op">=</span><span class="st">&#39;model&#39;</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a>plt.xlabel(<span class="st">&quot;x&quot;</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a>plt.ylabel(<span class="st">&quot;t&quot;</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true"></a>plt.legend()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true"></a>plt.show()</span></code></pre></div>
<p><img src="./myMediaFolder/f15f3347bd0823132f5e904dbe79cad0b8fae634.png" /></p>
<p>It is interesting to see how the model converges to the optimal solution. The following code shows this evolution, starting from a new random guess of the parameters:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a>w <span class="op">=</span> np.random.randn()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a>b <span class="op">=</span> np.random.randn()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a>num_iters <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a>eta <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a>    y <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a>    </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a>    plt.subplot(<span class="dv">4</span>, <span class="dv">4</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true"></a>    plt.plot(x, t, <span class="st">&#39;o&#39;</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true"></a>    plt.plot([xmin, xmax], [w<span class="op">*</span>xmin <span class="op">+</span> b, w<span class="op">*</span>xmax <span class="op">+</span> b], <span class="st">&#39;r-&#39;</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true"></a>    plt.xticks([])</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true"></a>    plt.yticks([])</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true"></a>    plt.title(<span class="st">&quot;epoch = </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> i)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true"></a>    </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true"></a>    y_minus_t <span class="op">=</span> y <span class="op">-</span> t</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true"></a>    dw <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t<span class="op">*</span>x)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true"></a>    db <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true"></a>    w <span class="op">-=</span> eta<span class="op">*</span>dw</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true"></a>    b <span class="op">-=</span> eta<span class="op">*</span>db</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true"></a>plt.show()</span></code></pre></div>
<p><img src="./myMediaFolder/8fcca8c23be670241b92a563daf0ecca84f3e6a7.png" /></p>
<p>Finally, we can observe this evolution in the <span class="math inline">\((w, b)\)</span> plane:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a>w <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a>b <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a>whistory <span class="op">=</span> [w]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>bhistory <span class="op">=</span> [b]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a>num_iters <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a>eta <span class="op">=</span> <span class="fl">0.0002</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iters):</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a>    y <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a>    </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a>    y_minus_t <span class="op">=</span> y <span class="op">-</span> t</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a>    dw <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t<span class="op">*</span>x)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a>    db <span class="op">=</span> np.<span class="bu">sum</span>(y_minus_t)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true"></a>    w <span class="op">-=</span> eta<span class="op">*</span>dw</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true"></a>    b <span class="op">-=</span> eta<span class="op">*</span>db</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true"></a>    whistory.append(w)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true"></a>    bhistory.append(b)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true"></a>    </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true"></a>wvalues <span class="op">=</span> np.arange(<span class="op">-</span><span class="fl">1.</span>, <span class="fl">5.01</span>, <span class="fl">0.01</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true"></a>bvalues <span class="op">=</span> np.arange(<span class="op">-</span><span class="fl">1.</span>, <span class="fl">3.01</span>, <span class="fl">0.01</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true"></a>bgrid, wgrid <span class="op">=</span> np.meshgrid(bvalues, wvalues)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true"></a>y <span class="op">=</span> wgrid[:, :, <span class="va">None</span>]<span class="op">*</span>x[<span class="va">None</span>, <span class="va">None</span>, :] <span class="op">+</span> bgrid[:, :, <span class="va">None</span>]</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true"></a>egrid <span class="op">=</span> np.<span class="bu">sum</span>((y<span class="op">-</span>t[<span class="va">None</span>, <span class="va">None</span>, :])<span class="op">**</span><span class="dv">2</span>, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true"></a>plt.contourf(bgrid, wgrid, egrid, <span class="dv">100</span>, cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)<span class="co">#</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true"></a>plt.plot(bhistory, whistory, <span class="st">&#39;-o&#39;</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true"></a>plt.plot(bhistory[<span class="op">-</span><span class="dv">1</span>], whistory[<span class="op">-</span><span class="dv">1</span>], <span class="st">&#39;yo&#39;</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true"></a>plt.xlabel(<span class="st">&#39;b&#39;</span>)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true"></a>plt.ylabel(<span class="st">&#39;w&#39;</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true"></a>plt.show()</span></code></pre></div>
<p><img src="./myMediaFolder/eea43c8d19bf99a4eb233c824a85db6968ae29ee.png" /></p>
<h3 id="questions"><font color="#CA3532">Questions</font></h3>
<ul>
<li>What happens if we increase the learning rate? Test with <span class="math inline">\(\eta = 0.0005\)</span>.</li>
<li>What happens if we decrease the learning rate? Test with <span class="math inline">\(\eta = 0.00001\)</span>.</li>
</ul>
<h2 id="linear-regression-in-arbitrary-dimension"><font color="#CA3532">Linear regression in arbitrary dimension</font></h2>
<p>In a more general situation we have a set of data <span class="math inline">\(({\bf x}_{i}, t_{i})\)</span> with <span class="math inline">\({\bf x}_{i} \in \mathbb{R}^{d}\)</span>. The model is:</p>
<p><span class="math display">\[y_{i} = {\bf w}^{t} {\bf x}_{i} + b,\]</span></p>
<p>where <span class="math inline">\({\bf w}\)</span> is also a <span class="math inline">\(d\)</span>-dimensional vector. Starting from random initial parameters <span class="math inline">\(({\bf w}_{0}, b_{0})\)</span>, the update rules are now:</p>
<p><span class="math display">\[{\bf w}_{t+1} = {\bf w}_{t} - \eta \nabla_{{\bf w}} E,\]</span></p>
<p><span class="math display">\[b_{t+1} = b_{t} - \eta \frac{\partial E}{\partial b},\]</span></p>
<p>where the gradients are given by the following expressions:</p>
<p><span class="math display">\[\nabla_{{\bf w}} E = \sum_{i}(y_{i} - t_{i}){\bf x}_{i},\]</span></p>
<p><span class="math display">\[\frac{\partial E}{\partial b} = \sum_{i}(y_{i} - t_{i}).\]</span></p>
<h3 id="exercise"><font color="#CA3532">Exercise</font></h3>
<ul>
<li>Extend the previous example to the multidimensional case.</li>
</ul>
</article>
</body>
</html>
