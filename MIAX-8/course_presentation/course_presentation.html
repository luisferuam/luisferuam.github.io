<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Luis F. Lago Fernández">
  <title>Introduction to (Deep) Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/theme/white.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h2 class="title">Introduction to<br>(Deep) Neural Networks</h2>
  <p class="author">Luis F. Lago Fernández</p>
  <p class="date">MIAX-8</p>
</section>

<section id="course-presentation" class="slide level3">
<h3>Course presentation</h3>
</section>
<section id="lecturers" class="slide level3">
<h3>Lecturers</h3>
<ul>
<li>Dr. Luis F. Lago Fernández
<ul>
<li>e-mail: <a href="mailto:luis.lago@uam.es">luis.lago@uam.es</a></li>
</ul></li>
<li>Christian Oliva Moya
<ul>
<li>e-mail: <a href="mailto:christian.oliva@uam.es">christian.oliva@uam.es</a></li>
</ul></li>
</ul>
</section>
<section id="learning-outcomes" class="slide level3">
<h3>Learning outcomes</h3>
<p align="left">
Upon completion of this course, you will be able to:
</p>
<ul>
<li>Understand the fundamentals of DL within the ML learning context</li>
<li>Train a DNN, choosing the most appropriate characteristics and optimizing the hyperparameters</li>
<li>Implement DL algorithms using different tools, such as TensorFlow, Keras or PyTorch</li>
</ul>
</section>
<section id="course-contents" class="slide level3">
<h3>Course contents</h3>
</section>
<section class="slide level3">

<ul>
<li><p>Introduction to Deep Learning</p></li>
<li><p>Machine learning fundamentals</p></li>
<li><p>Neural Network basics:</p>
<ul>
<li>Shallow neural networks</li>
<li>Backpropagation</li>
</ul></li>
<li><p>Deep Neural Networks:</p>
<ul>
<li>Practical aspects of deep learning: activation functions, loss functions, weight initialization</li>
<li>Batch normalization.</li>
<li>Regularization techniques, dropout</li>
</ul></li>
</ul>
</section>
<section class="slide level3">

<ul>
<li><p>Optimization techniques:</p>
<ul>
<li>Stochastic Gradient Descent</li>
<li>Adaptive methods</li>
</ul></li>
<li><p>Hyper-parameter tuning</p></li>
<li><p>Deep learning architectures:</p>
<ul>
<li>Convolutional neural networks</li>
<li>Recurrent neural networks</li>
<li>Autoencoders and GANs</li>
</ul></li>
<li><p>Deep Learning programming and parallelization tools: TensorFlow, Keras, PyTorch</p></li>
</ul>
</section>
<section id="bibliography" class="slide level3">
<h3>Bibliography</h3>
<ul>
<li><p>Deep Learning. I. Goodfellow, Y. Bengio and A. Courville. MIT Press, 2016. <a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></p></li>
<li><p>Neural Networks and Deep Learning. M. Nielsen. <a href="http://neuralnetworksanddeeplearning.com/">http://neuralnetworksanddeeplearning.com/</a></p></li>
<li><p>Hands-On Machine Learning with Scikit-Learn and TensorFlow. A. Geron. O’Reilly, 2017.</p></li>
<li><p>Deep Learning with Python. F. Chollet. Manning, 2017.</p></li>
</ul>
</section>
<section id="schedule" class="slide level3">
<h3>Schedule</h3>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr class="header">
<th>Day</th>
<th>Contents</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Day 1</td>
<td>Introduction and basic concepts<br>Machine Learning Fundamentals<br>Linear Regression<br>Gradient Descent</td>
</tr>
<tr class="even">
<td>Day 2</td>
<td>Logistic Regression<br>Non-linear models<br>Introduction to Neural Networks<br>NN Implementation (forward pass)</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="schedule-1" class="slide level3">
<h3>Schedule</h3>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr class="header">
<th>Day</th>
<th>Contents</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Day 3</td>
<td>Backpropagation<br>NN Implementation (backward pass)<br>Introduction to TensorFlow<br>Automatic Differentiation in TF</td>
</tr>
<tr class="even">
<td>Day 4</td>
<td>NN implementation in TF<br>Practical aspects of NN Training: SGD, loss function, activation function<br>Keras I</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="schedule-2" class="slide level3">
<h3>Schedule</h3>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr class="header">
<th>Day</th>
<th>Contents</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Day 5</td>
<td>Practical aspects of NN Training: regularization, weight initialization, batch normalization<br>Second order optimization techniques<br>Keras II</td>
</tr>
<tr class="even">
<td>Day 6</td>
<td>Hyperparameter optimization<br>Introduction to PyTorch</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="schedule-3" class="slide level3">
<h3>Schedule</h3>
<table>
<thead>
<tr class="header">
<th>Day</th>
<th>Contents</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Day 7</td>
<td>Deep Learning Architectures<br>Kohonen Networks<br>Practical Assignment</td>
</tr>
<tr class="even">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="additional-resources" class="slide level3">
<h3>Additional resources</h3>
<ul>
<li><p>Introduction to Deep Learning, MIT, <a href="http://introtodeeplearning.com/">http://introtodeeplearning.com/</a></p></li>
<li><p>Convolutional Neural Networks for Visual Recognition, Stanford, <a href="http://cs231n.stanford.edu/">http://cs231n.stanford.edu/</a></p></li>
<li><p>TensorFlow tutorials, <a href="https://www.tensorflow.org/tutorials/">https://www.tensorflow.org/tutorials/</a></p></li>
<li><p>TensorFlow Playground, <a href="http://playground.tensorflow.org">http://playground.tensorflow.org</a></p></li>
<li><p><a href="https://pytorch.org/tutorials/?utm_source=Google&amp;utm_medium=PaidSearch&amp;utm_campaign=%2A%2ALP+-+TM+-+General+-+HV+-+ES&amp;utm_adgroup=PyTorch+Tutorials&amp;utm_keyword=pytorch%20tutorials&amp;utm_offering=AI&amp;utm_Product=PyTorch&amp;gclid=CjwKCAjwkdL6BRAREiwA-kiczI5b2fCgZc0VAYKCMmEYQlq1eiTHKW1bi8RQQh-mfDoqRDg_J9AhqRoCjnMQAvD_BwE">PyTorch tutorials</a></p></li>
</ul>
</section>
<section id="recommendations" class="slide level3">
<h3>Recommendations</h3>
<ul>
<li>The following skills are highly recommended:
<ul>
<li>Calculus</li>
<li>Linear algebra</li>
<li>Statistics and probability theory</li>
<li>Python programming</li>
</ul></li>
</ul>
</section>
<section id="what-if-i-need-to-review-maths-concepts" class="slide level3">
<h3>What if I need to review maths concepts?</h3>
<ul>
<li>Chapters 2 and 3 of Goodfellow’s book:
<ul>
<li><a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Linear algebra</a></li>
<li><a href="https://www.deeplearningbook.org/contents/prob.html">Probability and information theory</a></li>
</ul></li>
<li><a href="http://cs229.stanford.edu/section/cs229-linalg.pdf">Linear Algebra Review and Reference</a>, Zico Kolter, 2015</li>
</ul>
</section>
<section id="what-if-i-need-to-review-programming-concepts" class="slide level3">
<h3>What if I need to review programming concepts?</h3>
<ul>
<li><a href="https://cs231n.github.io/python-numpy-tutorial/">Python Numpy Tutorial (with Jupyter and Colab)</a>, Justin Johnson</li>
</ul>
</section>
<section id="introduction-to-deep-learning" class="slide level3">
<h3>Introduction to deep learning</h3>
<ul>
<li>What is deep learning?</li>
<li>Why now?</li>
</ul>
</section>
<section id="what-is-deep-learning" class="slide level3">
<h3>What is Deep Learning?</h3>
<ul>
<li>A subfield of Machine Learning: learn without being explicitly programmed</li>
<li>Make predictions on data using Neural Networks</li>
<li>Deep neural networks: many layers</li>
</ul>
</section>
<section id="why-deep-learning-now" class="slide level3">
<h3>Why deep learning now?</h3>
<ul>
<li>Lots of data</li>
<li>Increase in computational power (parallelization, GPUs, …)</li>
<li>New programming tools, algorithms and tricks</li>
</ul>
</section>
<section id="machine-learning-basics" class="slide level3">
<h3>Machine Learning basics</h3>
<p>Suggested reading: <a href="https://www.deeplearningbook.org/contents/ml.html">https://www.deeplearningbook.org/contents/ml.html</a></p>
</section>
<section id="what-is-machine-learning" class="slide level3">
<h3>What is Machine Learning?</h3>
<ul>
<li><p>Field of study that gives computers the ability to learn without being explicitly programmed. (Attributed to <font color="#b3b0a1">A. Samuel, 1959</font>)</p></li>
<li><p>Subfield of AI that studies computer algorithms that improve automatically through experience. (<a href="https://en.wikipedia.org/wiki/Machine_learning">Wikipedia, 2020</a>)</p></li>
</ul>
</section>
<section id="different-learning-tasks" class="slide level3">
<h3>Different learning tasks</h3>
<ul>
<li><p><font color="#b3b0a1">Supervised</font> machine learning</p>
<ul>
<li>Classification</li>
<li>Regression</li>
</ul></li>
<li><p><font color="#b3b0a1">Unsupervised</font> machine learning</p></li>
<li><p><font color="#b3b0a1">Semi-supervised</font> machine learning</p></li>
<li><p><font color="#b3b0a1">Reinforcement</font> learning</p></li>
</ul>
</section>
<section id="supervised-machine-learning---definitions" class="slide level3">
<h3>Supervised machine learning - definitions</h3>
<ul>
<li><p>The problem data is the set of patterns <span class="math inline">\(\{({\bf x}_{1} , t_{1}), ({\bf x}_{2}, t_{2}), ..., ({\bf x}_{n}, t_{n})\}\)</span>, where:</p>
<ul>
<li><span class="math inline">\({\bf x}_{i}\)</span> is the <font color="#b3b0a1">attribute vector</font> for pattern <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(t_{i}\)</span> is the <font color="#b3b0a1">target</font> (variable to predict) for pattern <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(n\)</span> is the total number of patterns</li>
</ul></li>
<li><p>The goal is to predict the target <span class="math inline">\(t_{i}\)</span> given the attribute vector <span class="math inline">\({\bf x}_{i}\)</span></p></li>
</ul>
</section>
<section id="parametric-models-for-classification-regression" class="slide level3">
<h3>Parametric models for classification (regression)</h3>
<ul>
<li><p>A <font color="#b3b0a1">classifier (regressor)</font> is a function <span class="math inline">\(f({\bf x}, \theta)\)</span> that assigns each pattern <span class="math inline">\({\bf x}_i\)</span> an estimation of its target value: <span class="math inline">\(y_{i} = f({\bf x}_{i} , \theta) \approx t_{i}\)</span></p></li>
<li><p><font color="#b3b0a1">Model training</font>: tune the model parameters <span class="math inline">\(\theta\)</span> in order to minimize a <em>loss function</em> <span class="math inline">\(L(y_{i}, t_{i})\)</span></p></li>
<li><p>Different function families define different types of models: Neural Networks, SVMs, etc.</p></li>
</ul>
</section>
<section id="supervised-machine-learning---overview" class="slide level3">
<h3>Supervised machine learning - Overview</h3>
<p><img data-src="./Images/ML-algorithms.png" width="700" /></p>
</section>
<section id="supervised-machine-learning---an-example" class="slide level3">
<h3>Supervised machine learning - an example</h3>
<p>The <font color="#b3b0a1">Iris plant dataset</font> (R.A. Fisher, 1936)</p>
<p><img data-src="https://drive.google.com/uc?id=1aN5FeKpb1SBUhuglGNIe97-HFB0Naiaz" width="150" /></p>
<ul>
<li>Classify Iris plant samples into 3 subspecies: <em>Setosa</em>, <em>Virginica</em> and <em>Versicolor</em></li>
<li>Use the width and length of petal and sepal as attributes</li>
</ul>
</section>
<section id="supervised-machine-learning---an-example-1" class="slide level3">
<h3>Supervised machine learning - an example</h3>
<p>The <font color="#b3b0a1">Iris plant dataset</font> (R.A. Fisher, 1936)</p>
<p><img data-src="./Images/iris-table.png" width="500" /></p>
</section>
<section id="supervised-machine-learning---an-example-2" class="slide level3">
<h3>Supervised machine learning - an example</h3>
<p>The <font color="#b3b0a1">Iris plant dataset</font> (R.A. Fisher, 1936)</p>
<p><img data-src="./Images/iris-plots.png" width="700" /></p>
<p>Classification or regression?</p>
</section>
<section id="supervised-machine-learning---second-example" class="slide level3">
<h3>Supervised machine learning - second example</h3>
<p>The <font color="#b3b0a1">Boston Housing</font> problem</p>
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/d/d7/Boston_-_panoramio_%2823%29.jpg" width="700" /></p>
<ul>
<li>Predict housing prices in the suburbs of Boston</li>
</ul>
</section>
<section id="supervised-machine-learning---second-example-1" class="slide level3">
<h3>Supervised machine learning - second example</h3>
<p>The <font color="#b3b0a1">Boston Housing</font> problem</p>
<p><img data-src="./Images/boston-table.png" width="500" /></p>
</section>
<section id="supervised-machine-learning---second-example-2" class="slide level3">
<h3>Supervised machine learning - second example</h3>
<p>The <font color="#b3b0a1">Boston Housing</font> problem</p>
<p><img data-src="./Images/boston-plots.png" width="600" /></p>
<p>Classification or regression?</p>
</section>
<section id="the-ml-design-cycle" class="slide level3">
<h3>The ML design cycle</h3>
<p>Model construction/training is just one single step in a much bigger process</p>
<p><img data-src="./Images/ML-design-cycle.png" width="600" /></p>
</section>
<section id="model-evaluation-and-selection" class="slide level3">
<h3>Model evaluation and selection</h3>
<ul>
<li>How to assess the quality of a trained model</li>
<li>How to compare two different models</li>
<li>Model validation and hyper-parameter tuning</li>
<li>Different evaluation metrics: loss, accuracy, confusion matrix, ROC analysis, etc.</li>
</ul>
</section>
<section id="model-evaluation-and-selection---example" class="slide level3">
<h3>Model evaluation and selection - Example</h3>
<p><img data-src="./Images/duda-hart-two-models.png" width="700" /></p>
<p>Which model is better?</p>
</section>
<section id="model-complexity-and-generalization" class="slide level3">
<h3>Model complexity and generalization</h3>
<p><img data-src="./Images/overfitting.png" width="700" /></p>
<ul>
<li>Complex models are able to better adapt to the training data</li>
<li><em>Overfitting</em>: too much adaptation to the training data may lead to a poor generalization</li>
</ul>
</section>
<section id="training-validation-test" class="slide level3">
<h3>Training, validation, test</h3>
<p><img data-src="./Images/train-val-test.png" width="500" /></p>
<ul>
<li><p>Use different data for training and validating the model</p></li>
<li><p>Early stoping</p></li>
</ul>
</section>
<section id="proper-regularization" class="slide level3">
<h3>(Proper) Regularization</h3>
<ul>
<li><p>Modify the loss function by introducing a term that penalizes model complexity</p></li>
<li><p>LOSS = ERROR + COMPLEXITY</p></li>
</ul>
</section>
<section id="review-core-topics" class="slide level3">
<h3>Review: Core topics</h3>
<ul>
<li><p>DL is a subfield of ML that uses NNs to make predictions on data</p></li>
<li><p>NNs are supervised, parametric models that learn from examples (classification, regression)</p></li>
<li><p>Model training: tune the parameters in order to adapt to the training data</p></li>
<li><p>Model validation: complexity, generalization, overfitting, regularization</p></li>
</ul>
</section>
<section id="next" class="slide level3">
<h3>Next</h3>
<ul>
<li><p>Neural networks with one single neuron</p></li>
<li><p>Linear regression</p></li>
<li><p>Logistic regression (classification)</p></li>
</ul>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//dist/reveal.js"></script>

  // reveal.js plugins
  <script src="https://unpkg.com/reveal.js@^4//plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/zoom/zoom.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
      
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
